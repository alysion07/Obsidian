
WebGL에서 이미지를 그리려면 Texture를 사용해야함
Rendering 할 때 Pixel 좌표 대신 Clipspace 좌표를 예상하는것과 마찬가지로, 
일반적으로 Texture를 읽을때 Texture 좌표를 예상한다.

**Texture의 좌표는Texture의 크기에 상관없이** ==0.0 ~ 1.0==**의 크기를 가짐**

WebGL2에서는 Pixel의 좌표를 사용하여 Texture를 읽을 수 있는 기능 추가되었으나, 
Texture 좌표를 사용하는 것이 조금 더 일반적

---
## Load Image 

지금은 하나의 사각형(2개의 삼각형)을 그리기 때문에 WebGL에 직사각형의 각 점이 Texture의 어느 위치에 해당하는지 알려주어야 함. 이 정보를 V.S에서 F.S로 **'varying'**
이라 불리는 특별한 변수를 사용하여 전달함. varying은 값이 **변하기 때문**에 varying이라고 불림.

```cs title:'Vertex Shader' hl:1,3
in vec2 a_texCoord;

out vec2 v_texCoord; // varying value

void main() {
	// fragment shader로 texCoord 전달
	v_texCoord = a_texCoord;
}
```

```cs title:'Fragment Shader'
#version 300 es
precision highp float;
// 
uniform sampler2D u_image;

in vec2 v_texCoord; // from 'vertex shader'
out vec4 outColor;

void main() {
	// texture에서 색상을 찾는다.
	outColor = texture(u_image, v_texCoord);
}
```

마지막으로 이미지를 로드하고 텍스처를 생성한 뒤, 이미지를 텍스처로 복사해야 함. 우리는 **브라우저**를 사용하고 있기 때문에 **이미지가 비동기적으로 로딩**되고, 이를 위해 텍스처가 로드 될 때까지를 기다리도록 코드를 약간 변경

```js hl:1-7
function main(){
	var image = new Image();
	image.src = "https://someimage/on/our/server"; 
	image.onload = function() {
		render(image)
	}
}

function render(image) {
  ...
  var positionAttribLocation = gl.getAttribLocation(program, "a_position");
  var texCoordAttribLocation = gl.getAttribLocation(program, "a_texCoord");
  // uniform 
  var resolutionLocation = gl.getUniformLocation(program, "u_resolution");
  var imageLocation = gl.getUniformLocation(program, "u_iamge");
  ...
  
  var texCoordBuffer = gl.createBuffer();
  gl.bindBuffer(gl.ARRAY_BUFFER, texCoordBuffer);
  gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
    0.0, 0.0,
    1.0, 0.0,
    0.0, 1.0,
    0.0, 1.0,
    1.0, 0.0,
    1.0, 1.0 ]), gl.STATIC_DRAW);
  gl.enbleVertexAttribArray(texCoordibuteLocation);
  
  var size = 2;          
  var type = gl.FLOAT;   
  var normalize = false; 
  var stride = 0;      
  var offset = 0;        
  gl.vertexAttribPointer(
      texCoordAttributeLocation, size, type, normalize, stride, offset)
  
  //create texture
  var texture = gl.createTexture();
  // active texture unit 0   
  gl.activeTexture(gl.TEXTURE0 + 0);
  // 0에 textrue를 바인딩
  gl.bindTexture(gl.TEXTURE_2D, texture);
    // Set the parameters so we don't need mips and so we're not filtering
  // and we don't repeat
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
  
  //Upload the image into the texture.
  var miplevel = 0;
  var internalFormat = gl.RGBA;  //텍스처에 원하는 형식
  var srcFormat = gl.RGBA;       //우리가 제공하는 데이터 형식
  var srcType = gl.UNSIGNED_BYTE;
   gl.texImage2D(gl.TEXTURE_2D,
                 mipLevel,
                 internalFormat,
                 srcFormat,
                 srcType,
                 image);
                 
  gl.useProgram(program);
  
  // 셰이더에서 픽셀에서 클립공간으로 변환 할수 있도록
  // 캔버스 해상도를 전달합니다.
  gl.uniform1i(imageLocation, 0);
  // setRectangle에서 호출될 'gl.bufferData'가 
  //'positionBuffer'에 데이터를 넣도록 바인딩합니다
  gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);

  setRectangle(gl, 0, 0, image.width, image.height);


}
```
ref : https://webgl2fundamentals.org/webgl/webgl-2d-image.html

### 다른 픽셀값의 참조

 - WebGL은 0.0에서 1.0까지인 텍스처 좌표에서 텍스처들을 참조
 - 1픽셀 거리 : 텍스처 좌표 ->  `onePixel = 1.0 / textureSize`를 사용해 계산

아래는 **Blur**처리하는 Fragment Shader code (Blur : 각 픽셀의 왼쪽, 오른쪽 픽셀값을 사용해 **평균**을 냄)

 ```cs title:'Blur 처리하는 Fragment Shader' hl:22 ar:23
 #version 300 es
 
// 프래그먼트 셰이더는 정밀도 기본값이 없으므로 우리가 선택해야 합니다.
// highp가 대개 괜찮습니다. "높은 정밀도"를 의미합니다.
precision highp float;
 
// 텍스처
uniform sampler2D u_image;
 
// texCoord는 정점 셰이더에서 전달됩니다.
in vec2 v_texCoord;
 
// 프래그먼트 셰이더는 출력을 선언 해야합니다.
out vec4 outColor;
 
void main() {
  vec2 onePixel = vec2(1) / vec2(textureSize(u_image, 0));
 
  // 왼쪽, 중간, 오른쪽 픽셀의 평균을 계산합니다.
  outColor = (
      texture(u_image, v_texCoord) +
      texture(u_image, v_texCoord + vec2( onePixel.x, 0.0)) + // right
      texture(u_image, v_texCoord + vec2(-onePixel.x, 0.0)))  // left
      / 3.0;
}
```

### Convolution Kernel

```cs title:'Fragment Shader'
#version 300 es
precition high float;
uniform smapler2D u_iamge;

uniform float u_kernal[9];
uniform float u_kernalweight;

in vec2 v_texCoord;
out vec4 outColor;

void main() {
  vec2 onePixel = vec2(1) / vec2(textureSize(u_image, 0));
  vec4 colorSum =
     texture(u_image, v_texCoord + onePixel * vec2(-1, -1)) * u_kernel[0] +
     texture(u_image, v_texCoord + onePixel * vec2( 0, -1)) * u_kernel[1] +
     texture(u_image, v_texCoord + onePixel * vec2( 1, -1)) * u_kernel[2] +
     texture(u_image, v_texCoord + onePixel * vec2(-1,  0)) * u_kernel[3] +
     texture(u_image, v_texCoord + onePixel * vec2( 0,  0)) * u_kernel[4] +
     texture(u_image, v_texCoord + onePixel * vec2( 1,  0)) * u_kernel[5] +
     texture(u_image, v_texCoord + onePixel * vec2(-1,  1)) * u_kernel[6] +
     texture(u_image, v_texCoord + onePixel * vec2( 0,  1)) * u_kernel[7] +
     texture(u_image, v_texCoord + onePixel * vec2( 1,  1)) * u_kernel[8] ;
   outColor = vec4((colorSum / u_kernalweight).rgb, 1);
}
```

```js title:'JavaScript Code'
function computeKernelWeight(kernel) {
  var weight = kernel.reduce(function(prev, curr) {
    return prev + curr;
  });
  return weight <= 0 ? 1: weight;
}

...
var kernelLocation = gl.getUniformLocation(program, "u_kernel[0]");
var kernelWeightLocation = gl.getUniformLocation(program, "u_kernelWeight");
...
var edgeDetecrKernel = [
	-1, -1, -1,
	-1,  8, -1,
	-1, -1, -1
];

gl.uniform1fv(kernelLocation, edgeDetectKernel);
gl.uniform1f(kernelWeightLocation, computeKernelWeight(edgeDetectKernel));
```

reference: [Convolution of Bitmaps - CodeProject](https://www.codeproject.com/Articles/6534/Convolution-of-Bitmaps)
reference : https://docs.gimp.org/2.6/en/plug-in-convmatrix.html

## Texture Unit이란?

`gl.draw???`을 호출할 때 Shader는 Texture에 접근할 수 있음. 
Texture는 [[16.1. Texture Unit|Texture Unit]]에 바인딩 됨. 
디바이스 스펙에 따라 다르지만 기본적으로 WebGL2은 **16개**의 Texture Unit을을 지원함.

#### 각 샘플러 유닛이 참조하는 Texture Unit의 설정 
1. 샘플러 **uniform의 location**을 찾기
2. 참조하길 원하는 Texture Unit의 **인덱스를 설정**

```js title:"Get Location and set Unit Index "
var textureUnitIndex = 6; // texture unit 6 사용
var u_imageLoc = gl.getUniformLocation(program, "u_image");
gl.uniform1i(u_iamgeLoc, textureUnitIndex);
```

```js title:'Bind 'someTexture' to texture unit 6.'
gl.activeTexture(gl.TEXTURE6);
gl.bindTexture(gl.TEXTURE_2D, someTexture);
```


```js title:'This works Too'
var textureUnitIndex = 6; // use texture unit 6.
// Bind someTexture to texture unit 6.
gl.activeTexture(gl.TEXTURE0 + textureUnitIndex);
gl.bindTexture(gl.TEXTURE_2D, someTexture);
```

---

## GLSL 변수 a_, u_, v_ 접두어의 의미

단지 네이밍 컨벤션

- `a_`: 버퍼에서 제공된 데이터, **attribute**
- `u_`: 셰이더의 입력으로 제공되는 **uniform**
- `v_`: **V.S -> F.S** 로 전달, 각 픽셀이 그려지기 전에 정점 사이에서 보간 (또는 변화)되는값을 나타내는 **varying**

#convolution #birmap 